{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da19b28a",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "one of the main challenges was to clean the data, standardize it for input in the model.\n",
    "\n",
    "#### challenges\n",
    "unable to get the right dimensions from pick channels so i am going to play around a bit to see if i can achieve better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b573d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "import shutil \n",
    "import mne\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7b4543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(2021)\n",
    "np.random.seed(2021)\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=1, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1024, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.002, help=\"adam's learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.99, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=1, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--in_len\", type=int, default=2**10, help=\"length of the input fed to neural net\")\n",
    "# changing the signal channels to take 28 input channels\n",
    "# uncomment for 28\n",
    "# parser.add_argument(\"--in_channels\", type=int, default=27, help=\"number of signal channels\")\n",
    "parser.add_argument(\"--in_channels\", type=int, default=22, help=\"number of signal channels\")\n",
    "# changing the signal channels to output \n",
    "parser.add_argument(\"--outMotion_channels\", type=int, default=6, help=\"number of motion classes\")\n",
    "parser.add_argument(\"--outEmotion_channels\", type=int, default=3, help=\"number of emotion classes\")\n",
    "parser.add_argument(\"--chunk\", type=int, default=1000, help=\"length of splited chunks\")\n",
    "opt, unknown = parser.parse_known_args()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3757adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['HandStart', 'FirstDigitTouch', 'BothStartLoadPhase', 'LiftOff',\n",
    "       'Replace', 'BothReleased']\n",
    "chanelWant = ['Fp1', 'FC1', 'Fp2', 'P7', 'FC5', 'T7', 'F8', 'P4', 'CP5', 'P3', 'T8', 'Oz', 'FC6', 'O2', 'Cz', 'Fz', 'P8', 'C3', 'CP6', 'CP2', 'CP1', 'Pz', 'O1', 'F3', 'F7', 'C4', 'FC2', 'F4']\n",
    "\n",
    "with open('chanelID.pickle', 'rb') as f:\n",
    "    seedchanelWantId = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f4d29",
   "metadata": {},
   "source": [
    "there is some lexical change between the structures of both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f985570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chanelWant = ['CP5', 'P7', 'CP1', 'FP2', 'F4', 'P3', 'O1', 'FC5', 'FC1', 'T8', 'PZ', 'O2', 'FC6', 'T7', 'F7', 'F3', 'C4', 'FC2', 'CP6', 'F8', 'OZ', 'FZ', 'FP1', 'C3', 'CZ', 'CP2', 'P8', 'P4']\n",
    "# print(mne.pick_channels(ch_names=eeg_raw.info['ch_names'],include = chanelWant))\n",
    "# chWantId = mne.pick_channels(ch_names=eeg_raw.info['ch_names'],include = chanelWant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d28c222",
   "metadata": {},
   "source": [
    "## SEED \n",
    "enotion based dataset,\n",
    "has 3 emotions.\n",
    "1. Fear\n",
    "2. Neutral\n",
    "3. Other\n",
    "\n",
    "divided into 3 sessions with 15 trials each, each trial encompasses a subject watching a clip that induces a certain emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fada892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c2a056674e48da8277f310678086fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/52 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Loading SEED Data\n",
    "# the fear trainset\n",
    "## - Fear is 1 , Neutral is 2, Other is 0\n",
    "\n",
    "#Session 1:\n",
    "start_secondOne= [30, 132, 287, 555, 773, 982, 1271, 1628, 1730, 2025, 2227, 2435, 2667, 2932, 3204]\n",
    "end_secondOne= [102, 228, 524, 742, 920, 1240, 1568, 1697, 1994, 2166, 2401, 2607, 2901, 3172, 3359]\n",
    "\n",
    "#Session 2:\n",
    "start_secondTwo= [30, 299, 548, 646, 836, 1000, 1091, 1392, 1657, 1809, 1966, 2186, 2333, 2490, 2741]\n",
    "end_secondTwo= [267, 488, 614, 773, 967, 1059, 1331, 1622, 1777, 1908, 2153, 2302, 2428, 2709, 2817]\n",
    "\n",
    "#Session 3:\n",
    "start_secondThree= [30, 353, 478, 674, 825, 908, 1200, 1346, 1451, 1711, 2055, 2307, 2457, 2726, 2888]\n",
    "end_secondThree= [321, 418, 643, 764, 877, 1147, 1284, 1418, 1679, 1996, 2275, 2425, 2664, 2857, 3066]\n",
    "\n",
    "SeedTrainset = []\n",
    "SeedValidset = []\n",
    "\n",
    "def extractEEG(data,timestampBegin,timestampEnd,num,signal = 0):\n",
    "    \n",
    "    dum = (data[:,timestampBegin[num]*1000: timestampEnd[num]*1000])\n",
    "    signalArray = np.zeros((1,dum.shape[1]))\n",
    "    \n",
    "    if signal == 1:\n",
    "        signalArray[0,:] = 1\n",
    "    elif signal == 2:\n",
    "        signalArray[1,:] = 1\n",
    "    else:\n",
    "        signalArray[2,:] = 1\n",
    "        \n",
    "    \n",
    "    return ([signalArray,dum.astype(np.float32)])\n",
    "\n",
    "## need to extract features according to fear, Other and Neutral\n",
    "#seedTrainset = []\n",
    "\n",
    "#data_trial_2 = data_matrix[:,start_second[1]*1000 : end_second[1]*1000]\n",
    "#print(data_trial_2.shape)\n",
    "\n",
    "for filename in tqdm(os.listdir('../SEED-V/SEED-V/EEG_raw')):\n",
    "    data_file_name = os.path.join('../SEED-V/SEED-V/EEG_raw', filename)\n",
    "    if filename.split('.')[1] != 'cnt':\n",
    "        continue\n",
    "    x = mne.io.read_raw_cnt(data_file_name,)\n",
    "    data_matrix = x.get_data()\n",
    "    \n",
    "    d = np.take(data_matrix,seedchanelWantId,axis=0)\n",
    "\n",
    "    if (filename.split('_')[1]) == '1':\n",
    "        for i in range(15):            \n",
    "            if i in [1, 6,11]:\n",
    "                SeedTrainset.append(extractEEG(d,start_secondOne,end_secondOne,i,1))\n",
    "            elif i in [3,8,15]:\n",
    "                SeedTrainset.append(extractEEG(d,start_secondOne,end_secondOne,i,2))\n",
    "            else:\n",
    "                SeedTrainset.append(extractEEG(d,start_secondOne,end_secondOne,i,0))\n",
    "\n",
    "    # second trial\n",
    "    elif (filename.split('_')[1])=='2':\n",
    "        for i in range(15):\n",
    "            if i in [1,9,12]: \n",
    "                SeedTrainset.append(extractEEG(d,start_secondOne,end_secondOne,i,1))\n",
    "            elif i in [3,8,11]:\n",
    "                SeedTrainset.append(extractEEG(d,start_secondOne,end_secondOne,i,2))\n",
    "            else:\n",
    "                SeedTrainset.append(extractEEG(d,start_secondOne,end_secondOne,i,0))\n",
    "\n",
    "    # third trial\n",
    "    else:\n",
    "        for i in range(15):\n",
    "            if i in [1,6,12]:\n",
    "                SeedValidset.append(extractEEG(d,start_secondOne,end_secondOne,i,1))\n",
    "            elif i in [3,8,11]:\n",
    "                SeedValidset.append(extractEEG(d,start_secondOne,end_secondOne,i,2))\n",
    "            else:\n",
    "                SeedValidset.append(extractEEG(d,start_secondOne,end_secondOne,i,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfcf956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Seeddata.pickle', 'wb') as f:\n",
    "    pickle.dump(SeedTrainset, f)\n",
    "with open('Seedvaliddata.pickle','wb') as f:\n",
    "    pickle.dump(SeedValidset,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b39afb4",
   "metadata": {},
   "source": [
    "## Grasp and lift detection\n",
    "Motion dataset\n",
    "6 ranges of motion\n",
    "subject go through the trial and their eeg is observed when they are performing an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b31b7e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a72136236d91468ea8556e5ad6081067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading in test data just sample of 96 files\n",
    "def read_csv(data, events):\n",
    "    x = pd.read_csv(data)\n",
    "    y = pd.read_csv(events)\n",
    "    id = '_'.join(x.iloc[0, 0].split('_')[:-1])\n",
    "    x = x[chanelWant].values\n",
    "    y = y.iloc[:,1:].values\n",
    "    return x, y\n",
    "    \n",
    "\n",
    "trainset = []\n",
    "gt = []\n",
    "i = 0\n",
    "for filename in tqdm(os.listdir('./train')):\n",
    "    if i<=96:\n",
    "        if 'data' in filename:\n",
    "            data_file_name = os.path.join('./train', filename)\n",
    "            id = filename.split('.')[0]\n",
    "            events_file_name = os.path.join('./train', '_'.join(id.split('_')[:-1]) + '_events.csv')\n",
    "            x, y = read_csv(data_file_name, events_file_name)\n",
    "            trainset.append(x.T.astype(np.float32))\n",
    "            gt.append(y.T.astype(np.float32))\n",
    "        i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "230399bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping it into pickle\n",
    "with open('trainset.pickle','wb') as f:\n",
    "    pickle.dump(trainset,f)\n",
    "with open('labels.pickle','wb') as f:\n",
    "    pickle.dump(gt,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d76bf4",
   "metadata": {},
   "source": [
    "## Reading the dataset from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e99d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "with open('trainset.pickle','rb') as f:\n",
    "    trainset = pickle.load(f)\n",
    "with open('labels.pickle','rb') as f:\n",
    "    gt = pickle.load(f)\n",
    "with open('Seeddata.pickle', 'rb') as f:\n",
    "    Seedtrainset = pickle.load(f)\n",
    "with open('Seedvaliddata.pickle', 'rb') as f:\n",
    "    SeedValidset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0eeb0e",
   "metadata": {},
   "source": [
    "## quick check if the dimensions issue has been resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa605906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 209212)\n",
      "(28, 72000)\n",
      "(28, 72000)\n"
     ]
    }
   ],
   "source": [
    "# shapes\n",
    "print(trainset[0].shape)\n",
    "print(SeedTrainset[0][1].shape)\n",
    "print(SeedValidset[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4a94f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "480\n",
      "240\n"
     ]
    }
   ],
   "source": [
    "# lengths of the list\n",
    "print(len(trainset))\n",
    "print(len(SeedTrainset))\n",
    "print(len(SeedValidset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee42f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "607d4332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8823943\n",
      "81730640\n",
      "40761480\n"
     ]
    }
   ],
   "source": [
    "# check if the lengths of the rows are similar to see how much do i need to alternate the dimensions to fit within the model.\n",
    "motionsum = 0\n",
    "for i in trainset:\n",
    "    motionsum+= i.shape[1]\n",
    "print (motionsum)\n",
    "\n",
    "seedsum = 0\n",
    "for i in SeedTrainset:\n",
    "    seedsum+= i[1].shape[1]\n",
    "print(seedsum)\n",
    "\n",
    "seedvalidsum = 0\n",
    "for i in SeedValidset:\n",
    "    seedvalidsum+=i[1].shape[1]\n",
    "print(seedvalidsum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3acafb9",
   "metadata": {},
   "source": [
    " Well as we can see clearly there are some size issues to deal with, as expected. I am planning on resolving these issues using batch sizes.\n",
    " \n",
    " *but* on the brighter side the issue with eeg  channels has been resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2990d04a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
